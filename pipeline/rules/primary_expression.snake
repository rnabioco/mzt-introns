
""" calculate primary expression levels """ 

    
def _map_settings(wildcards):
  """ lookup global dictionary LIB_MAP via sample
      wildcard and return settings for salmon 
      based on experiment definition in config file 
  """
  id = os.path.basename(wildcards.sample)
  if id in LIB_MAP:
     lib_attrs = LIB_MAP[id]
     map_settings = config[lib_attrs]["map"]
  else:
     print("WARNING: no map settings found for library: {}".format(id),
       file = sys.stderr)
     map_settings = ""

  return map_settings


def _fq_types(wildcards):
  """ lookup global dictionary LIB_MAP via sample
      and lookup fastq suffixes
  """
  id = os.path.basename(wildcards.sample)
  if id in LIB_MAP:
     lib_attrs = LIB_MAP[id]
     fq_types = config[lib_attrs]["fq"]
     
     if len(fq_types) == 1:
       suffixes = [""]
     elif len(fq_types) > 1:
       suffixes = ["_R1", "_R2"]
     fq_names = [path.join(wildcards.data,
                           "fastq",
                           "trimmed",
                           wildcards.species, 
                           wildcards.expt, 
                           wildcards.sample + x + "_trimmed.fastq.gz") for
                           x in suffixes]
  else:
     sys.exit("no fastq suffixes found for library: {}".format(id))

  return fq_names

def _input_options(wildcards):
  
  fqs = _fq_types(wildcards)
  if len(fqs) == 1:
      io_option = " -r {fq[0]} ".format(fq = fqs)
  elif len(fqs) > 1:
      io_option = " -1 {fq[0]} -2 {fq[1]} ".format(fq = fqs)
  else:
      sys.exit("no fastq suffixes found for library: {}".format(id))
  return io_option
    
rule salmon_idx:
    """
    build salmon on pre-mRNA fasta
    Salmon v0.9.1
    """
    input:
      fasta = path.join(DBASES, "{species}",  "primary_transcripts.fa"),
      gtf = path.join(DBASES, "{species}", "primary_transcripts.gtf")
    output:
      path.join(DBASES, "{species}", "salmon", "hash.bin")
    params:
      outname = path.join(DBASES, "{species}", "salmon"),
      idx_settings = lambda wildcards: SALMON_K[wildcards.species],
      job_name = "salmon_idx",
      memory = "select[mem>50] rusage[mem=50]",
    log:
      path.join(DBASES, "logs", "{species}", "generate_primary_transcript_salmon_index.txt")
    threads: 12
    resources: all_threads=12
    shell:
      """
      salmon index \
        -p {threads} \
        -t {input.fasta} \
        --type "quasi" \
        -k {params.idx_settings} \
        -i {params.outname}
      """

rule salmon_primary:
    """
    run salmon on pre-mRNA indexes
    Salmon v0.9.1
    """
    input:
      idx = path.join(DBASES, "{species}", "salmon", "hash.bin"),
      R1 = _fq_types,
      #R1 = "{data}/fastq/trimmed/{species}/{expt}/{sample}_trimmed.fastq.gz",
      gtf = path.join(DBASES, "{species}", "primary_transcripts.gtf")
    output:
      q = path.join("{data}", "salmon", "{species}", "{expt}", "{sample}",
              "quant.sf"),
      bam = path.join("{data}", "salmon", "{species}", "{expt}",
              "{sample}", "quasi.bam"),
      bai = path.join("{data}", "salmon", "{species}", "{expt}",
              "{sample}", "quasi.bam.bai")
    params:
      io = _input_options,
      settings = _map_settings,
      idx = path.join(DBASES, "{species}", "salmon"),
      out_dir = path.join("{data}", "salmon", "{species}", "{expt}", "{sample}"),
      job_name = "salmon_fishin",
      memory = "select[mem>30] rusage[mem=30]",
    log:
      path.join("{data}", "salmon", "logs", "{species}", "{expt}", "{sample}")
    threads: 12
    resources: all_threads=12
    shell:
      """
      salmon quant \
        -i {params.idx} \
        {params.settings} \
        {params.io} \
        -o {params.out_dir} \
        -p {threads} \
        --numBootstraps 50 \
        -z \
        -g {input.gtf}  \
        | samtools view -@ 4 -bS - \
        | samtools sort -@ 4 - \
        > {output.bam}

        samtools index -@ 4 {output.bam}
      """

rule salmon_masked_idx:
    """
    build salmon on pre-mRNA fasta
    Salmon v0.9.1
    """
    input:
      tx_fasta = path.join(DBASES, "{species}",  "{fasta}.fa"),
      genome_fasta = lambda wildcards: GENOMES[wildcards.species],
    output:
      path.join(DBASES, "{species}", "salmon", "{fasta}", "pos.bin")
    params:
      outname = path.join(DBASES, "{species}", "salmon", "{fasta}"),
      idx_settings = lambda wildcards: SALMON_K[wildcards.species],
      chroms = lambda wildcards: CHROM_SIZES[wildcards.species],
      job_name = "salmon_idx",
      memory = "select[mem>50] rusage[mem=50]",
    log:
      path.join(DBASES, "logs", "{species}", "generate_primary_transcript_" + "{fasta}.txt")
    threads: 12
    resources: all_threads=12
    shell:
      """
      # make temp decoys file
      # make temp transcriptome + genome
      
      cut -f 1 {params.chroms} > {input.tx_fasta}.tmp.decoys
      cat {input.tx_fasta} {input.genome_fasta} > {input.tx_fasta}.tmp.fa
      salmon index \
        -p {threads} \
         --keepFixedFasta \
        -t {input.tx_fasta}.tmp.fa \
        -d {input.tx_fasta}.tmp.decoys \
        -k {params.idx_settings} \
        -i {params.outname}

      rm {input.tx_fasta}.tmp.decoys {input.tx_fasta}.tmp.fa

      """

rule salmon_primary_masked:
    """
    run salmon on pre-mRNA indexes
    Salmon v0.9.1
    """
    input:
      idx = path.join(DBASES, "{species}", "salmon", "{fasta}", "pos.bin"),
      R1 = _fq_types,
    output:
      q = path.join("{data}", "salmon", "{species}", "{expt}", "{fasta}",
              "{sample}", "quant.sf"),
      bam = path.join("{data}", "salmon", "{species}", "{expt}",
              "{fasta}",
              "{sample}", "quasi.bam")
    params:
      io = _input_options,
      settings = _map_settings,
      idx = path.join(DBASES, "{species}", "salmon", "{fasta}"),
      out_dir = path.join("{data}", "salmon", "{species}", "{expt}", "{fasta}", "{sample}"),
      job_name = "salmon_fishin",
      memory = "select[mem>50] rusage[mem=50]",
    log:
      path.join("{data}", "salmon", "logs", "{species}", "{expt}", "{sample}")
    threads: 12
    resources: all_threads=12
    shell:
      """
      salmon quant \
        -i {params.idx} \
        {params.settings} \
        {params.io} \
        -o {params.out_dir} \
        -p {threads} \
        --numBootstraps 50 \
        --validateMappings \
        -z \
        --dumpEq \
        -d \
        | samtools view -@ 4 -bS - \
        | samtools sort -@ 4 - \
        > {output.bam}

      samtools index {output.bam}
      """

rule salmon_primary_requant:
    """
    run salmon on pre-mRNA indexes with subtracted intronic intervals
    from maternal samples
    """
    input:
      q = path.join("{data}", "salmon", "{species}", "{expt}", "{fasta}",
              "{sample}", "quant.sf"),
      bam = path.join("{data}", "salmon", "{species}", "{expt}",
              "{fasta}",
              "{sample}", "quasi.bam"),
      mask = path.join(DBASES, "{species}", "intron_mask",
              "eisa_unique_transcripts.tsv"),
      fa = path.join(DBASES, "{species}", "{fasta}.fa")
    output:
      q = path.join("{data}", "salmon", "{species}", "{expt}", "{fasta}",
              "{sample}_requant", "quant.sf"),
      bam = path.join("{data}", "salmon", "{species}", "{expt}",
              "{fasta}",
              "{sample}_requant", "quasi_minus_introns.bam")
    params:
      settings = _map_settings,
      out_dir = path.join("{data}", "salmon", "{species}", "{expt}",
              "{fasta}", "{sample}_requant"),
      job_name = "salmon",
      memory = "select[mem>50] rusage[mem=50]",
    log:
      path.join("{data}", "salmon", "logs", "{species}", "{expt}",
              "{sample}_requant")
    threads: 12
    resources: all_threads=12
    shell:
      """
      bedtools subtract -S -split -a {input.bam} \
              -b {input.mask} \
              > {output.bam}

      salmon quant \
              -t {input.fa} \
              {params.settings} \
              -a {output.bam} \
              -o {params.out_dir} \
              -p {threads} \
              --numBootstraps 50
      """

#rule primary_transcript_gtf:
#    """
#    Append primary transcript records to GTF annotations
#    src/add_primary_transcripts.py
#    and extract out transcript.fa
#    """
#    input:
#      lambda wildcards: TRANSCRIPTS[wildcards.species]
#    output:
#      gtf = path.join(DBASES, "{species}", "primary_transcripts.gtf"), 
#      fa = path.join(DBASES, "{species}" ,"primary_transcripts.fa") 
#    params:
#      genome = lambda wildcards: GENOMES[wildcards.species],
#      job_name = "gen_primary_txs",
#      memory = "select[mem>4] rusage[mem=4]",
#    log:
#      path.join(DBASES, "logs", "{species}", "generate_primary_transcript_db.txt")
#    resources: all_threads=1
#    shell:
#      """
#      python3 {SRC}/add_primary_transcripts.py \
#        -i {input} \
#        -r "gene" \
#        -a "gene_id" > {output.gtf}
#
#      gffread -w {output.fa} -g {params.genome} {output.gtf}
#      """
